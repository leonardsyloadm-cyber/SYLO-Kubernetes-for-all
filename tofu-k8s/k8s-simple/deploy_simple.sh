#!/bin/bash
set -e
cd "$(dirname "$0")"

# Recibimos el ID de la orden desde el Orquestador
ORDER_ID=$1

# Variables de entorno
CLUSTER_NAME="ClienteBronce-$ORDER_ID"
BUZON_STATUS="$HOME/proyecto/buzon-pedidos/status_$ORDER_ID.json"
TF_VAR_nombre="$CLUSTER_NAME"
export TF_VAR_nombre

# --- FUNCIÃ“N PARA GESTIONAR ERRORES ---
handle_error() {
    echo "âŒ Error crÃ­tico en la lÃ­nea $1"
    echo "{\"percent\": 100, \"message\": \"Error crÃ­tico en el despliegue. Revisa los logs del servidor.\", \"status\": \"error\"}" > "$BUZON_STATUS"
    # No hacemos exit aquÃ­ para permitir que el trap termine limpiamente, pero el proceso morirÃ¡
}
# Si hay un error, ejecutamos la funciÃ³n
trap 'handle_error $LINENO' ERR

# --- FUNCIÃ“N PARA ACTUALIZAR ESTADO EN LA WEB ---
update_status() {
    local percent=$1
    local msg=$2
    # Escribimos el JSON que leerÃ¡ el PHP/JS
    echo "{\"percent\": $percent, \"message\": \"$msg\", \"status\": \"running\"}" > "$BUZON_STATUS"
    # Feedback en la terminal del orquestador
    echo "ðŸ“Š [Progreso $percent%] $msg"
}

# ==============================================================================
# INICIO DEL PROCESO
# ==============================================================================

# 0% - Inicio
update_status 0 "Iniciando maquinaria de despliegue..."

# Limpieza de candados y clÃºsteres previos
sudo rm -f /tmp/juju-* 2>/dev/null
if minikube profile list 2>/dev/null | grep -q "$CLUSTER_NAME"; then
    update_status 5 "Limpiando instalaciÃ³n anterior..."
    sudo minikube delete -p "$CLUSTER_NAME" > /dev/null 2>&1
fi

# 25% - Creando VM
update_status 20 "Provisionando mÃ¡quina virtual (Minikube)..."
# Usamos sudo + force para evitar errores de permisos de Docker
(sudo minikube start -p "$CLUSTER_NAME" \
    --driver=docker \
    --cpus=2 \
    --memory=1024m \
    --addons=default-storageclass \
    --interactive=false \
    --force) > /dev/null 2>&1

# 40% - ConfiguraciÃ³n de Red y Permisos
update_status 40 "Configurando certificados y contexto..."

# --- ARREGLO DE PERMISOS (Vital para que Tofu funcione) ---
sudo rm -rf "$HOME/.minikube"
sudo cp -r /root/.minikube "$HOME/"
sudo chown -R "$USER":"$USER" "$HOME/.minikube"

mkdir -p "$HOME/.kube"
sudo cp /root/.kube/config "$HOME/.kube/config"
sudo chown "$USER":"$USER" "$HOME/.kube/config"

# Reemplazamos la ruta de root por la de usuario en el config
sed -i "s|/root/.minikube|$HOME/.minikube|g" "$HOME/.kube/config"
# ---------------------------------------------------------

kubectl config use-context "$CLUSTER_NAME" > /dev/null

# 60% - OpenTofu
update_status 60 "Inicializando motor OpenTofu..."
# Generamos contraseÃ±a segura para el cliente
SSH_PASS=$(openssl rand -base64 12)

rm -f terraform.tfstate terraform.tfstate.backup
tofu init -upgrade > /dev/null

update_status 70 "Desplegando Pod SSH (VPS Simulado)..."
tofu apply -auto-approve -var="nombre=$CLUSTER_NAME" -var="ssh_password=$SSH_PASS" > /dev/null

# 90% - Espera final
update_status 85 "Esperando IP pÃºblica y asignaciÃ³n de puertos..."
# Esperamos a que el deployment estÃ© listo
kubectl wait --for=condition=available --timeout=90s deployment/ssh-server > /dev/null

# RecopilaciÃ³n de datos finales
update_status 95 "Finalizando configuraciÃ³n..."

# Obtenemos la IP (En local es la de Minikube, en prod serÃ­a tu IP pÃºblica)
# Para que el comando funcione con sudo minikube, a veces hay que especificar el perfil
HOST_IP=$(sudo minikube ip -p "$CLUSTER_NAME")
# Obtenemos el puerto NodePort asignado desde el output de Tofu
NODE_PORT=$(tofu output -raw ssh_port)

CMD_SSH="ssh cliente@$HOST_IP -p $NODE_PORT"

# 100% - FINALIZADO
# Escribimos el JSON final con los datos de conexiÃ³n. La web detectarÃ¡ "completed" y mostrarÃ¡ la ventana verde.
echo "{\"percent\": 100, \"message\": \"Â¡ClÃºster Creado!\", \"status\": \"completed\", \"ssh_cmd\": \"$CMD_SSH\", \"ssh_pass\": \"$SSH_PASS\"}" > "$BUZON_STATUS"

echo "âœ… Despliegue Bronce completado para Orden #$ORDER_ID."